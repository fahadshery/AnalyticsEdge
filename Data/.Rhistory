str(news)
summary(news)
table(news$popular)
105/nrow(news)
prop.table(news$popular)
prop.table(table(news$popular)
prop.table(table(news$popular))
prop.table(table(news$popular))
cor(news$word.count, news$popular)
cor(news)
cor(news$popular, news$word.count)
str(news$headline)
cor(news$popular, length(news$headline)
cor(news$popular, length(news$headline))
cor(news$popular, length(news$headline))
for(i in 1:973){
news$headline.word.count[i] <- length(news$headline[i])
}
news$headline.word.count
for(i in 1:973){
news$headline.word.count[i] <- nchar(news$headline[i])
}
news$headline.word.count
cor(news$popular, news$headline.word.count))
cor(news$popular, news$headline.word.count)
class(news$headline)
install.packages("stringr")
library(stringr)
test = as.character(c("My name is Fahad", "Her name is Annum"))
test
class(test)
news$headline
test = as.character(c("My name is Fahad", "Her name is Annum", "Rish is my sis"))
test
word(test,start=1L, end=start)
word(test,start=1L)
word(test,start=1L, sep=fixed(" "))
word(news$headline)
news$headline
cor(news$popular, news$headline.word.count)
news$popular = as.factor(news$popular)
news$type = as.factor(news$type)
str(news)
library(caTools)
set.seed(144)
spl = sample.split(news$popular, SplitRatio=0.7)
train = subset(news,spl==TRUE)
test = subset(news,spl == FALSE)
LogModel = glm(popular ~ print + type + word.count, data=train, family=binomial)
summary(LogModel)
str(train$type)
train$type
-0.8468333 * 1 + 0.9055929*2 + 682*0.0002600
682*0.0002600
0.9055929*2
-0.8468333 * 1 + 0.9055929*1 + 682*0.0002600
summary(LogModel)
-0.8468333 * 1 + 0.9055929*2 + 682*0.0002600
-2.5075573 -0.8468333 * 1 + 0.9055929*1 + 682*0.0002600
exp(-2.271478)/(1 + exp(-2.271478))
LogRegPred = predict(LogModel, newdata=test, type="response")
table(test$popular, LogRegPred >= 0.5)
LogRegPred
table(test$popular, LogRegPred >= 0.5)
table(test$popular)
260/nrow(test)
summary(LogRegPred)
library(ROCR)
pred = prediction(LogRegPred, test$popular)
as.numeric(performance(pred, "auc")@y.values)
library(ROCR)
ROCRperf = performance(pred, "tpr", "fpr")
plot(ROCRperf)
plot(ROCRperf,colorize=TRUE)
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.01), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.2), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.15), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.5), text.adj=c(-0.2,1.7))
plot(ROCRperf,colorize=TRUE,  print.cutoffs.at=seq(0,1,by=0.09), text.adj=c(-0.2,1.7))
set.seed(144)
library(caret)
library(e1071)
tree.control = trainControl(method="cv", number=10)
50 * 0.01
cp.grid = expand.grid(.cp = seq(0.01, 0.5, 0.01) )
tr= train(popular ~ print + type + word.count , data=train, method="rpart", trControl=tree.control, tuneGrid=cp.grid)
library(rpart)
tr= train(popular ~ print + type + word.count , data=train, method="rpart", trControl=tree.control, tuneGrid=cp.grid)
tr
popular.Tree.CP = rpart(popular ~ . , data=train, control=rpart.control(cp=0.01))
popular.Tree.CP = rpart(popular ~ . ,method="class", data=train, control=rpart.control(cp=0.01))
prp(popular.Tree.CP)
library(rpart)
library(rpart.plot)
popular.Tree.CP = rpart(popular ~ . ,method="class", data=train, control=rpart.control(cp=0.01))
prp(popular.Tree.CP)
popular.Tree.CP = rpart(popular ~ print + type + word.count ,method="class", data=train, control=rpart.control(cp=0.01))
prp(popular.Tree.CP)
library(tm)
corpusTitle = Corpus(VectorSource(news$snippet))
corpus = Corpus(VectorSource(news$snippet))
rm(corpusTitle)
corpusAdded
corpus
corpus[[1]]
corpus[[2]]
corpus[[3]]
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus[[1]]
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
dtm = DocumentTermMatrix(corpus)
dtm
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
articleText = as.data.frame(as.matrix(spdtm))
str(articleText)
sort(colSums(articleText))
summary(articleText)
articleText$print = news$print
articleText$type = news$type
articleText$word.count = news$word.count
articleText$popular = news$popular
str(articleText)
trainText = subset(articleText, spl==TRUE)
testText = subset(articleText, spl==FALSE)
glmText = glm(popular ~ . , data=trainText, family=binomial)
summary(LogModel)
trainText
summary(glmText)
LogRegPred2 = predict(glmText, newdata=testText, type="response")
pred2 = prediction(LogRegPred2, testText$popular)
as.numeric(performance(pred2, "auc")@y.values)
as.numeric(performance(pred, "auc")@y.values)
table(testText$popular, LogRegPred2 >= 0.5)
summary(LogRegPred2)
stocks = read.csv("nasdaq_returns.csv")
str(stocks)
summary(stocks)
table(stocks$stock_symbol)
head(stocks)
sum(table(stocks$stock_symbol))
table(stocks$industry)
str(stocks)
stocks$ret2000.12
sort(stocks$ret2000.12)
1153-850
tapply(stocks$ret2000.12,stocks$stock_symbol, sum)
sort(tapply(stocks$ret2000.12,stocks$stock_symbol, sum))
sum(table(stocks$ret2000.10))
sum(table(stocks$stock_symbol))
sum(table(stocks$stock_symbol, stocks$ret2000.10))
table(stocks$stock_symbol, stocks$ret2000.10))
table(stocks$stock_symbol, stocks$ret2000.10)
str(stocks)
sort(tapply(stocks$ret2000.12,stocks$stock_symbol, sum))
sort(table(tapply(stocks$ret2000.12,stocks$stock_symbol, sum)))
sort(stocks$ret2000.12>0.10)
sum(sort(stocks$ret2000.12>0.10))
sum(sort(stocks$ret2000.12>=0.10))
sum(sort(stocks$ret2000.12<=-0.10))
table(stocks$industry, stocks$ret2008.10)
sort(table(stocks$industry, stocks$ret2008.10))
stocks$ret2008.10
tapply(stocks$ret2008.10,stocks$industry,sum)
sort(tapply(stocks$ret2008.10,stocks$industry,sum))
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2000.02,stocks$industry,sum))
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,mean))
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,sum))
tapply(stocks$ret2008.10,stocks$industry,mean)
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
sort(tapply(stocks$ret2008.10,stocks$industry,mean))
limited = stocks
limited$stock_symbol = NULL
limited$industry = NULL
limited$subindustry = NULL
str(limited)
which.max(mean(limited))
mean(limited)
col_names = colnames(limited)
col_names
res = data.frame()
for(i in col_names){
res$col_name = i
res$mean = mean(limited[i])
}
limited[ret2000.01]
limited$ret2000.01
head(limited)
head(limited[,1])
res = data.frame(ID=limited[,1], Means=rowMeans(limited[,-1]))
str(res)
sort(res$Means)
rm(res)
rm(col_names)
rm(i)
sor(colMeans(limited)
sor(colMeans(limited))
sor(colMeans(limited))
sort(colMeans(limited))
which.max(colMeans(limited))
which.min(colMeans(limited))
setwd("~/R Projects/Data")
dailyKOS = read.csv("dailykos.csv")
str(dailyKOS)
class(dailyKOS)
limitedMatrix = as.matrix(limited)
str(limitedMatrix)
limitedVector = as.vector(limitedMatrix)
str(limitedVector)
dailyKOSMatrix = as.matrix(dailyKOS)
str(dailyKOSMatrix)
dailyKOSVector = as.vector(dailyKOSMatrix)
str(dailyKOSVector)
dailyKOS = read.csv("dailykos.csv")
dailyKOSMatrix = as.matrix(dailyKOS)
dailyKOSVector = as.vector(dailyKOSMatrix)
str(dailyKOSVector)
str(dailyKOSMatrix)
3430*1546
str(dailyKOSVector)
distance = dist(limited, method="euclidean")
LimitedClusters = hclust(distance, method="ward")
LimitedClusters
plot(LimitedClusters)
rm(dailyKOS)
rm(dailyKOSMatrix)
rm(dailyKOSVector)
cluster5 = cutree(LimitedClusters, k=5)
table(cluster5)
sort(table(cluster5))
cluster1 = subset(limited, cluster5 == 1)
cluster2 = subset(limited, cluster5 == 2)
cluster3 = subset(limited, cluster5 == 3)
cluster4 = subset(limited, cluster5 == 4)
cluster5 = subset(limited, cluster5 == 5)
cluster1 = subset(stocks, cluster5 == 1)
cluster2 = subset(stocks, cluster5 == 2)
cluster3 = subset(stocks, cluster5 == 3)
cluster4 = subset(stocks, cluster5 == 4)
cluster5 = subset(stocks, cluster5 == 5)
cluster3
table(cluster5)
table(cluster5)
sort(table(cluster5))
cluster5 = cutree(LimitedClusters, k=5)
rm(cluster1)
rm(cluster2)
rm(cluster3)
rm(cluster4)
rm(cluster5)
cluster5 = cutree(LimitedClusters, k=5)
sort(table(cluster5))
cluster5
STR(cluster5)
str(cluster5)
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
fileList
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
str(completeCases)
df <- data.frame(matrix(unlist(completeCases),byrow=T))
df
str(df)
completeCases
str(completeCases)
res = data.frame()
length(completeCases)
res = vector()
res
res = numeric()
for(i in 1:length(completeCases)){
if(nrow(completeCases[[i]])>=117){
res[i] = cor(completeCases[[i]]$sulfate,completeCases[[i]]$niterate)
}
}
completeCasesMatrix = as.matrix(completeCases)
completeCasesMatrix
str(completeCasesMatrix)
length(completeCasesMatrix)
nrow(completeCasesMatrix[1])
nrow(completeCasesMatrix[[1]])
for(i in 1:length(completeCasesMatrix)){
if(nrow(completeCasesMatrix[[i]])>=117){
res[i] = cor(completeCasesMatrix[[i]]$sulfate,completeCasesMatrix[[i]]$niterate)
}
}
completeCasesDF = as.list.data.frame(completeCases)
completeCasesDF
str(completeCasesDF)
completeCasesDF = as.data.frame(completeCases)
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
completeCases
str(completeCases)
Datadf = do.call(rbind.data.frame,completeCases)
Datadf
length(Datadf)
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
str(completeCases)
res = numeric()
res2 = data.frame()
res2 <- as.data.frame(completeCases[[1]])
res2
res[1] <- cor(res2$sulfate, res2$nitrate)
res
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
res = numeric()
str(completeCases)
if(nrow(completeCases[[1]])>=117){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[1]])
res[1] <- cor(res2$sulfate, res2$nitrate)
res2 = NULL
res[1]
}
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
str(completeCases)
res = numeric()
if(nrow(completeCases[[1]])>=117){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[1]])
res[1] <- cor(res2$sulfate, res2$nitrate)
rm(res2)
res[1]
}
if(nrow(completeCases[[2]])>=1041){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[2]])
res[2] <- cor(res2$sulfate, res2$nitrate)
rm(res2)
res[2]
}
res
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
res = numeric()
for(i in 1:length(completeCases)){
if(nrow(completeCases[[i]])>=150){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[i]])
res[i] <- cor(res2$sulfate, res2$nitrate)
rm(res2)
res[i]
}
}
res
head(res)
res = res[!is.na(res)]
head(res)
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
res = numeric()
for(i in 1:length(completeCases)){
if(nrow(completeCases[[i]])>=400){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[i]])
res[i] <- cor(res2$sulfate, res2$nitrate)
rm(res2)
res[i]
}
}
res = res[!is.na(res)]
res
head(res)
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
res = numeric()
for(i in 1:length(completeCases)){
if(nrow(completeCases[[i]])>=5000){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[i]])
res[i] <- cor(res2$sulfate, res2$nitrate)
rm(res2)
res[i]
}
}
res = res[!is.na(res)]
head(res)
summary(res)
length(res)
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/specdata"
fileList = list.files(path)
Data = lapply(file.path(path,fileList),read.csv)
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
res = numeric()
for(i in 1:length(completeCases)){
if(nrow(completeCases[[i]])>=0){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[i]])
res[i] <- cor(res2$sulfate, res2$nitrate)
rm(res2)
res[i]
}
}
res = res[!is.na(res)]
head(res)
summary(res)
length(res)
corr <- function(directory, threshold = 0) {
#set the path
path = "C:/Users/Fahad/Documents/R Projects/Coursera/R-Programming-Coursera/Data/"
path = c(path,directory)
path = paste(path,collapse="")
#get the file List in that directory
fileList = list.files(path)
#import data
Data = lapply(file.path(path,fileList),read.csv)
#get the complete cases
completeCases = lapply(Data, function(Data) Data[complete.cases(Data),])
#create a dataframe to return the results
res = numeric()
#compare the no. of obs in complete cases against threshold and calculate
#correlations and save results in the res vector
for(i in 1:length(completeCases)){
if(nrow(completeCases[[i]])>=threshold){
res2 = data.frame()
res2 <- as.data.frame(completeCases[[i]])
res[i] <- cor(res2$sulfate, res2$nitrate)
rm(res2)
}
}
res = res[!is.na(res)]
res
}
head(corr("specdata",400)
head(corr("specdata",400))
head(corr("specdata",400))
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
setwd("~/R Projects/Coursera/r-programming-coursera/Code/Assignments")
submit()
9
submit()
submit()
stocks = read.csv("nasdaq_returns.csv")
setwd("~/R Projects/AnalyticsEdge/Data")
stocks = read.csv("nasdaq_returns.csv")
str(stocks)
summary(stocks)
sum(table(stocks$stock_symbol))
table(stocks$industry)
sum(sort(stocks$ret2000.12>=0.10))
sum(sort(stocks$ret2000.12<=-0.10))
sort(tapply(stocks$ret2008.10,stocks$industry,mean))
sort(tapply(stocks$ret2000.02,stocks$industry,mean))
limited = stocks
limited$stock_symbol = NULL
limited$industry = NULL
limited$subindustry = NULL
str(limited)
sort(colMeans(limited))
which.min(colMeans(limited))
limited(106)
limited[106]
which.min(colMeans(limited))
limitedMatrix = as.matrix(limited)
limitedVector = as.vector(limitedMatrix)
str(limitedVector)
distance = dist(limited, method="euclidean")
distance
LimitedClusters = hclust(distance, method="ward")
plot(LimitedClusters)
clusters = cutree(LimitedClusters, k=5)
str(clusters)
sort(table(clusters))
table(clusters)
sort(tapply(stocks, clusters, mean))
sort(tapply(limited, clusters, mean))
sort(tapply(limited$ret2000.01, clusters, mean))
lapply(split(limited, clusters), colMeans)
tail(lapply(split(limited, clusters), colMeans))
sort(tapply(limited$ret2000.02, clusters, mean))
sort(tapply(limited$ret2000.03, clusters, mean))
sort(tapply(limited$ret2005.05, clusters, mean))
sort(tapply(limited$ret2009.10, clusters, mean))
sort(tapply(limited$ret2009.12, clusters, mean))
set.seed(144)
LimitedKMC = kmeans(limited, centers=5)
str(LimitedKMC)
table(LimitedKMC$cluster)
sort(table(LimitedKMC$cluster))
sort(table(clusters))
table(clusters, LimitedKMC$cluster)
